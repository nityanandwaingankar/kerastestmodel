{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7ca7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, MaxPooling2D,Flatten,Dropout,Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2277f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load('Inputdata/X_train.npy')\n",
    "y_train = load('Inputdata/y_train.npy')\n",
    "X_test = load('Inputdata/X_test.npy')\n",
    "y_test = load('Inputdata/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25112097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****X_TRAIN*****\n",
      "(60000, 28, 28)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "*****Y_TRAIN*****\n",
      "(60000,)\n",
      "5\n",
      "*****X_TEST*****\n",
      "(10000, 28, 28)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.32941176 0.7254902  0.62352941 0.59215686 0.23529412 0.14117647\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.87058824 0.99607843 0.99607843 0.99607843 0.99607843 0.94509804\n",
      "  0.77647059 0.77647059 0.77647059 0.77647059 0.77647059 0.77647059\n",
      "  0.77647059 0.77647059 0.66666667 0.20392157 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2627451  0.44705882 0.28235294 0.44705882 0.63921569 0.89019608\n",
      "  0.99607843 0.88235294 0.99607843 0.99607843 0.99607843 0.98039216\n",
      "  0.89803922 0.99607843 0.99607843 0.54901961 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.06666667\n",
      "  0.25882353 0.05490196 0.2627451  0.2627451  0.2627451  0.23137255\n",
      "  0.08235294 0.9254902  0.99607843 0.41568627 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3254902  0.99215686 0.81960784 0.07058824 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08627451\n",
      "  0.91372549 1.         0.3254902  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.50588235\n",
      "  0.99607843 0.93333333 0.17254902 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23137255 0.97647059\n",
      "  0.99607843 0.24313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.52156863 0.99607843\n",
      "  0.73333333 0.01960784 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03529412 0.80392157 0.97254902\n",
      "  0.22745098 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.49411765 0.99607843 0.71372549\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29411765 0.98431373 0.94117647 0.22352941\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0745098  0.86666667 0.99607843 0.65098039 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.79607843 0.99607843 0.85882353 0.1372549  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14901961 0.99607843 0.99607843 0.30196078 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.12156863\n",
      "  0.87843137 0.99607843 0.45098039 0.00392157 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.52156863\n",
      "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23921569 0.94901961\n",
      "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4745098  0.99607843\n",
      "  0.99607843 0.85882353 0.15686275 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4745098  0.99607843\n",
      "  0.81176471 0.07058824 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "******Y_TEST*****\n",
      "(10000,)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(\"*****X_TRAIN*****\")\n",
    "print(X_train.shape)\n",
    "print(X_train[0])\n",
    "print(\"*****Y_TRAIN*****\")\n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n",
    "print(\"*****X_TEST*****\")\n",
    "print(X_test.shape)\n",
    "print(X_test[0])\n",
    "print(\"******Y_TEST*****\")\n",
    "print(y_test.shape)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc3bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X_train = (60000, 28, 28)\n",
      "Original shape of X_test = (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original shape of X_train =\", X_train.shape)\n",
    "print(\"Original shape of X_test =\", X_test.shape, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a0b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train to (60000, 784) and X_test to (10000, 784)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcafe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape of X_train = (60000, 784)\n",
      "new shape of X_test = (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"new shape of X_train =\", X_train.shape)\n",
    "print(\"new shape of X_test =\", X_test.shape, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd434fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert target (y_train and y_test) into one-hot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "temp = []\n",
    "for i in range(len(y_train)):\n",
    "    temp.append(to_categorical(y_train[i], num_classes=10))\n",
    "    \n",
    "y_train = np.array(temp)\n",
    "temp = []\n",
    "for i in range(len(y_test)):\n",
    "    temp.append(to_categorical(y_test[i], num_classes=10))\n",
    "\n",
    "y_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and train sequential model\n",
    "# model_seq = Sequential()\n",
    "# model_seq.add(Dense(5, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "# model_seq.add(Dense(4, activation='sigmoid'))\n",
    "# model_seq.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model_seq.summary()\n",
    "\n",
    "# model_seq.compile(loss='categorical_crossentropy', \n",
    "#                   optimizer='adam', \n",
    "#                   metrics=['acc'])\n",
    "\n",
    "# model_seq.fit(X_train, y_train, epochs=3, \n",
    "#               validation_data=(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6514d938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create eval pd.df \n",
    "targets = np.where(y_test == np.amax(y_test))[1]\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c7a227",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.8102 - accuracy: 0.7577 - val_loss: 0.4603 - val_accuracy: 0.8634\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.4650 - accuracy: 0.8607 - val_loss: 0.4109 - val_accuracy: 0.8771\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.4195 - accuracy: 0.8759 - val_loss: 0.3774 - val_accuracy: 0.8862\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3964 - accuracy: 0.8821 - val_loss: 0.3618 - val_accuracy: 0.8926\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8861 - val_loss: 0.3560 - val_accuracy: 0.8921\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3700 - accuracy: 0.8886 - val_loss: 0.3596 - val_accuracy: 0.8919\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3624 - accuracy: 0.8914 - val_loss: 0.3385 - val_accuracy: 0.8976\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3555 - accuracy: 0.8931 - val_loss: 0.3420 - val_accuracy: 0.8956\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3507 - accuracy: 0.8950 - val_loss: 0.3296 - val_accuracy: 0.9008\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3433 - accuracy: 0.8976 - val_loss: 0.3283 - val_accuracy: 0.9011\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8977 - val_loss: 0.3361 - val_accuracy: 0.8988\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3342 - accuracy: 0.8999 - val_loss: 0.3218 - val_accuracy: 0.9040\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3299 - accuracy: 0.9009 - val_loss: 0.3188 - val_accuracy: 0.9056\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3278 - accuracy: 0.9017 - val_loss: 0.3189 - val_accuracy: 0.9031\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3230 - accuracy: 0.9030 - val_loss: 0.3333 - val_accuracy: 0.8970\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3212 - accuracy: 0.9034 - val_loss: 0.3167 - val_accuracy: 0.9051\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3172 - accuracy: 0.9039 - val_loss: 0.3288 - val_accuracy: 0.8989\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3136 - accuracy: 0.9054 - val_loss: 0.3161 - val_accuracy: 0.9023\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3120 - accuracy: 0.9058 - val_loss: 0.3159 - val_accuracy: 0.9036\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3099 - accuracy: 0.9057 - val_loss: 0.3204 - val_accuracy: 0.9019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19aaf684190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, activation='sigmoid', input_shape=(X_train.shape[1],))),\n",
    "model.add(Dense(128, activation='relu')),\n",
    "model.add(Dropout(0.2)),\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "#       model.add(Flatten(input_shape=(784))),\n",
    "#       model.add(Dense(128, activation='relu')),\n",
    "#       model.add(Dropout(0.2)),\n",
    "#       model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb3f9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "model.add(Lambda(lambda x: K.cast(K.argmax(x), dtype='float32'), name='y_pred'))\n",
    "model.save('data/trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb3fec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53095233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/23 18:12:42 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp9zaji_5v\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp9zaji_5v\\model\\data\\model\\assets\n",
      "2023/01/23 18:12:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp9zaji_5v\\model, flavor: tensorflow), fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/01/23 18:12:51 DEBUG mlflow.utils.environment: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\modelenv\\lib\\site-packages\\mlflow\\utils\\environment.py\", line 391, in infer_pip_requirements\n",
      "    return _infer_requirements(model_uri, flavor)\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\modelenv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 381, in _infer_requirements\n",
      "    modules = _capture_imported_modules(model_uri, flavor)\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\modelenv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 284, in _capture_imported_modules\n",
      "    _run_command(\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\modelenv\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 213, in _run_command\n",
      "    stderr = stderr.decode(\"utf-8\")\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x95 in position 2177: invalid start byte\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "2023/01/23 18:12:51 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/23 18:12:52 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as multiclass dataset, number of classes is inferred as 10\n",
      "2023/01/23 18:12:57 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Permutation is used.\n",
      "2023/01/23 18:12:57 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: ValueError('max_evals=500 is too low for the Permutation explainer, it must be at least 2 * num_features + 1 = 1029!'). Set logging level to DEBUG to see the full traceback.\n",
      "2023/01/23 18:12:57 DEBUG mlflow.models.evaluation.default_evaluator: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\modelenv\\lib\\site-packages\\mlflow\\models\\evaluation\\default_evaluator.py\", line 745, in _log_model_explainability\n",
      "    shap_values = explainer(sampled_X)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\shap\\explainers\\_permutation.py\", line 82, in __call__\n",
      "    return super().__call__(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\shap\\explainers\\_explainer.py\", line 266, in __call__\n",
      "    row_result = self.explain_row(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\shap\\explainers\\_permutation.py\", line 164, in explain_row\n",
      "    raise ValueError(f\"max_evals={max_evals} is too low for the Permutation explainer, it must be at least 2 * num_features + 1 = {2 * len(inds) + 1}!\")\n",
      "ValueError: max_evals=500 is too low for the Permutation explainer, it must be at least 2 * num_features + 1 = 1029!\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(X_test)\n",
    "df['target'] = targets\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "#mlflow evaluation\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.tensorflow.log_model(model, \"model\")\n",
    "    result = mlflow.evaluate(\n",
    "       model_info.model_uri,\n",
    "       df,\n",
    "       targets=\"target\",\n",
    "       model_type=\"classifier\",\n",
    "       #dataset_name=\"adult\",\n",
    "       evaluators=[\"default\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d89c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693aa7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76c79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5ca1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2115399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c2c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf268465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b6b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelenv",
   "language": "python",
   "name": "modelenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
